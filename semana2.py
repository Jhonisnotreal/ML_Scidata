# -*- coding: utf-8 -*-
"""Semana2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NNK4WFzBbnoiDMTKM6KeDKfw3eXsIRWO

#Regresion Logistica

Son mas sencillas que las regresiones lineales UuU
"""

#!pip install siuba

import os
import pandas as pd
import numpy as np
from siuba import *
from siuba.dply.vector import *
from plotnine import *
from sklearn.linear_model import LinearRegression

ruta = 'https://raw.githubusercontent.com/scidatmath2020/ML_Py_23/main/data/cancer_mama.csv'
data = pd.read_csv(ruta)
print(data.shape)
print(data.columns)
#print(data.info())

print(data >> group_by(_.diagnosis) >> summarize(conteo_objetivo = n(_), porcentaje_objetivo = n(_)/data.shape[0]))
#n(_) cuenta cuantos renglones hay
data = data >> mutate(diagnosis = _.diagnosis.replace({0:1,1:0}))
#remplaze el 0 por 1 y el 1 por el 0 â†‘ porque por convencion buscamos los valores que sean 1s

print(data >> group_by(_.diagnosis) >> summarize(conteo_objetivo = n(_), porcentaje_objetivo = n(_)/data.shape[0]))

data_peor_area = data >> select(_.worst_area,_.diagnosis)

(ggplot(data = data_peor_area) +
    geom_point(mapping = aes(x="worst_area", y="diagnosis"),color="red")
 )

modelo_reg_lineal = LinearRegression()
modelo_reg_lineal.fit(X=data_peor_area >> select(_.worst_area),
                      y=data_peor_area >> select(_.diagnosis))

data_peor_area = data_peor_area >> mutate(predicciones_reg_lineal = modelo_reg_lineal.predict(data_peor_area >> select(_.worst_area)))

(ggplot(data = data_peor_area) +
    geom_point(mapping = aes(x="worst_area", y="diagnosis"),color="red") +
    geom_line(mapping = aes(x="worst_area", y="predicciones_reg_lineal"),color="blue")
 )

"""La regresion lineal no considera que los datos son categoricos por eso no nos sirve en este ejemplo
\n
Quiero predecir la etiqueta 0 (cancer benigno) no el numero 0
"""

from sklearn.linear_model import LogisticRegression

modelo_reg_logis = LogisticRegression()

modelo_reg_logis.fit(X=data_peor_area >> select(_.worst_area), y=data_peor_area["diagnosis"])

data_peor_area = data_peor_area >> mutate(probabilidades_reg_logis = (modelo_reg_logis.predict_proba(data_peor_area >> select(_.worst_area)))[:,1])
#probabilidades de pertenecer al 0 o al 1
#el [:,1] es para solo tomar la parte derecha que es para la probabilidad de cancer maligno

modelo_reg_logis.predict_proba(data_peor_area >> select(_.worst_area))
#la izquierda es la probabilidad de que sea 0 (benigno), la derecha es la probabilidad de que sea maligno

#print(data[:])

(ggplot(data = data_peor_area) +
    geom_point(mapping = aes(x="worst_area", y="diagnosis"),color="red") +
    geom_line(mapping = aes(x="worst_area", y="predicciones_reg_lineal"),color="blue") +
    geom_line(mapping = aes(x="worst_area", y="probabilidades_reg_logis"),color="darkgreen")
 )

"""â†‘ La regresion logistica usualmente da la etiqueta (0 o 1), en el grafico de arriba nos da la probabilidad"""

data_peor_area = data_peor_area >> mutate(prediccion = modelo_reg_logis.predict(data_peor_area >> select(_.worst_area)))
# â†‘ Da la etiqueta de 0 o 1 como tal

data_peor_area

"""# Regresion Logistica"""

data = pd.read_csv('https://raw.githubusercontent.com/scidatmath2020/ML_Py_23/main/data/cancer_mama.csv')

data = data >> mutate(diagnosis = _.diagnosis.replace({0:1,1:0}))

data.shape

from sklearn.model_selection import train_test_split
from sklearn import metrics

variables_independientes = data >> select(-_.diagnosis)
objetivo = data >> select(_.diagnosis)

indepen_entrenamiento, indepen_prueba, objetivo_entrenamiento, objetivo_prueba = train_test_split(variables_independientes,
                                                                                                  objetivo,
                                                                                                  test_size=0.3,
                                                                                                  random_state=42)

modelo_rl = LogisticRegression(solver = "newton-cholesky")
# â†‘ conviene cuando tienes mas filas que columnas
modelo_rl.fit(indepen_entrenamiento,objetivo_entrenamiento.values.ravel())
# â†‘ el .values.ravel es para que sea lista de 1 array 1Dimension en lugar de 1 dataframe
# de una dimesion porque no lo agarra

predicciones = modelo_rl.predict(indepen_prueba) #La zona azul clara del excel del profe
predicciones_probabilidades = modelo_rl.predict_proba(indepen_prueba)
objetivos_reales = objetivo_prueba.values.ravel()

def tupla_clase_prediccion(y_real, y_pred):
    return list(zip(y_real, y_pred))

tupla_clase_prediccion(objetivos_reales, predicciones)[:20]

#â†‘ el [:20] es para mostrar los primeros 20

"""Validar una regresion

"""

def VP(clases_reales, predicciones):
    par_clase_prediccion = tupla_clase_prediccion(clases_reales, predicciones)
    return len([obs for obs in par_clase_prediccion if obs[0]==1 and obs[1]==1])

def VN(clases_reales, predicciones):
    par_clase_prediccion = tupla_clase_prediccion(clases_reales, predicciones)
    return len([obs for obs in par_clase_prediccion if obs[0]==0 and obs[1]==0])

def FP(clases_reales, predicciones):
    par_clase_prediccion = tupla_clase_prediccion(clases_reales, predicciones)
    return len([obs for obs in par_clase_prediccion if obs[0]==0 and obs[1]==1])

def FN(clases_reales, predicciones):
    par_clase_prediccion = tupla_clase_prediccion(clases_reales, predicciones)
    return len([obs for obs in par_clase_prediccion if obs[0]==1 and obs[1]==0])

print("""
Verdaderos Positivos: {}
Verdaderos Negativos: {}
Falsos Positivos: {}
Falsos Negativos: {}
""".format(
    VP(objetivos_reales, predicciones),
    VN(objetivos_reales, predicciones),
    FP(objetivos_reales, predicciones),
    FN(objetivos_reales, predicciones)
))

'''
Verdaderos Positivos de la tabla de prueba que si son malignos
Verdaderos Negativos son benignos
Falsos Positivos parecia ser maligno pero son benignos en realidad
Falsos Negativos parecia benigno pero en realidad era maligno ðŸ˜±
'''

"""# Metricas de evaluacion"""

'''Exactitud (accuracy)'''
metrics.accuracy_score(objetivos_reales, predicciones)

'''PrecisiÃ³n'''

def precision(clases_reales, predicciones):
    vp = VP(clases_reales, predicciones)
    fp = FP(clases_reales, predicciones)
    return vp / (vp+fp)

precision(objetivos_reales, predicciones)

'''Sensibilidad'''

metrics.recall_score(objetivos_reales, predicciones)

'''PuntuaciÃ³n F1'''

metrics.f1_score(objetivos_reales, predicciones)